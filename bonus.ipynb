{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# Helper libraries\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def read_data(image_path, label_path):\n",
    "    with open(image_path,'rb') as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "        print(\"label size: \", size)\n",
    "        \n",
    "        data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        data = data.reshape((size, nrows*ncols))\n",
    "        \n",
    "    with open(label_path, 'rb') as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        print(\"label size: \", size)\n",
    "        labels = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label size:  60000\n",
      "label size:  60000\n",
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"train-images-idx3-ubyte\"\n",
    "label_path = \"train-labels-idx1-ubyte\"\n",
    "images, labels = read_data(image_path, label_path)\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb46b4c450>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test \n",
    "print(labels[0])\n",
    "plt.imshow(images[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"random\" in \"random_hi\"\n",
    "#\"random\" in \"r_hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build determined W first \n",
    "class MnistClassification():\n",
    "    def __init__(self, input_size, hidden_size, learning_rate, net_struct, forward_only=True):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.net_struct = net_struct\n",
    "        self.forward_only = forward_only\n",
    "        self.print_ops = []\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        \n",
    "        # build\n",
    "        self._build_placeholder()\n",
    "        self._build_graph_and_get_loss()\n",
    "        \n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "    def _build_placeholder(self):\n",
    "        self.images = tf.placeholder(dtype=tf.float32, shape=(None, self.input_size), name=\"images\")\n",
    "        self.labels = tf.placeholder(dtype=tf.int32, shape=(None), name=\"labels\")\n",
    "        if \"random\" in self.net_struct:\n",
    "            self.random_1 = tf.placeholder(dtype=tf.float32, shape=(self.input_size, self.hidden_size), name='r1')\n",
    "            self.random_2 = tf.placeholder(dtype=tf.float32, shape=(self.hidden_size, self.hidden_size), name='r2')\n",
    "            self.random_3 = tf.placeholder(dtype=tf.float32, shape=(self.hidden_size, 10), name='r3')\n",
    "            \n",
    "    def _build_graph_and_get_loss(self):\n",
    "        # get variables\n",
    "        if \"random\" not in self.net_struct:\n",
    "            self.W1 = tf.Variable(tf.random_normal([self.input_size, self.hidden_size], stddev=0.35), name=\"W1\")\n",
    "            self.W2 = tf.Variable(tf.random_normal([self.hidden_size, self.hidden_size], stddev=0.35), name=\"W2\")\n",
    "            self.W3 = tf.Variable(tf.random_normal([self.hidden_size, 10], stddev=0.35), name=\"W3\")\n",
    "        else:\n",
    "            self.mu_1 = tf.Variable(tf.random_normal([self.input_size, self.hidden_size], stddev=0.35), name=\"mu1\")\n",
    "            self.rho_1 = tf.Variable(tf.random_normal([self.input_size, self.hidden_size], stddev=0.35), name=\"rho1\")\n",
    "            \n",
    "            self.mu_2 = tf.Variable(tf.random_normal([self.hidden_size, self.hidden_size], stddev=0.35), name=\"mu_2\")\n",
    "            self.rho_2 = tf.Variable(tf.random_normal([self.hidden_size, self.hidden_size], stddev=0.35), name=\"rho_2\")\n",
    "            \n",
    "            self.mu_3 = tf.Variable(tf.random_normal([self.hidden_size, 10], stddev=0.35), name=\"mu_3\")\n",
    "            self.rho_3 = tf.Variable(tf.random_normal([self.hidden_size, 10], stddev=0.35), name=\"rho_3\")\n",
    "            \n",
    "            # build graph\n",
    "            self.W1 = self.mu_1 + self.random_1 * tf.math.sqrt(tf.math.log(1 + tf.math.exp(self.rho_1)))\n",
    "            self.W2 = self.mu_2 + self.random_2 * tf.math.sqrt(tf.math.log(1 + tf.math.exp(self.rho_2)))\n",
    "            self.W3 = self.mu_3 + self.random_3 * tf.math.sqrt(tf.math.log(1 + tf.math.exp(self.rho_3)))\n",
    "            \n",
    "        self.tmp = None\n",
    "        self.y = None \n",
    "        # build graph \n",
    "        self.tmp = tf.matmul(self.images, self.W1)\n",
    "        self.tmp = tf.nn.relu(self.tmp, name=\"relu1\")\n",
    "\n",
    "        self.tmp = tf.matmul(self.tmp, self.W2)\n",
    "        self.tmp = tf.nn.relu(self.tmp, name=\"relu2\")\n",
    "\n",
    "        self.y = tf.matmul(self.tmp, self.W3)\n",
    "        self.y = tf.nn.softmax(self.y, axis=1) + 1e-7\n",
    "        \n",
    "        # create one hot encoding for labels\n",
    "        self.one_hot_labels = tf.one_hot(self.labels, depth=10)\n",
    "        #self.print_ops.append(tf.print(\"labels: \", self.labels, tf.shape(self.labels)))\n",
    "        #self.print_ops.append(tf.print(\"One hot labels: \", self.one_hot_labels, tf.shape(self.one_hot_labels)))\n",
    "        \n",
    "        # compute loss\n",
    "        self.loss = tf.reduce_sum(-tf.math.log(self.y) * self.one_hot_labels)\n",
    "        #self.print_ops.append(tf.print(\"mask: \", -tf.math.log(self.y) * self.one_hot_labels))\n",
    "        #self.print_ops.append(tf.print(\"the step loss: \", self.loss))\n",
    "        \n",
    "        # check whether the model can overfit the train batch\n",
    "        self.preds = tf.cast(tf.argmax(self.y, axis=1), dtype=tf.int32)\n",
    "        self.accu = tf.reduce_sum(tf.cast(tf.equal(self.preds, self.labels), dtype=tf.float32)) / \\\n",
    "                                    tf.cast(tf.shape(self.preds)[0], tf.float32)\n",
    "        #self.print_ops.append(tf.print(\"preds: \", self.preds, tf.shape(self.preds)))\n",
    "        #self.print_ops.append(tf.print(\"labels: \", self.labels, tf.shape(self.labels)))\n",
    "        \n",
    "        if not self.forward_only:\n",
    "            # apply gradients \n",
    "            self.update = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.loss,global_step=self.global_step)\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        \n",
    "        \n",
    "    def step(self, session, input_feed, forward_only):\n",
    "        if not forward_only:\n",
    "            output_feed = [self.loss, self.accu, self.update, self.print_ops]\n",
    "        else:\n",
    "            output_feed = [self.accu]\n",
    "        \n",
    "        outputs = session.run(output_feed, input_feed)\n",
    "        \n",
    "        if not forward_only:\n",
    "            return outputs[0], outputs[1]\n",
    "        else:\n",
    "            return outputs[0]\n",
    "        \n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, model, image_path, label_path, batch_size):\n",
    "        self.model = model\n",
    "        self.image_path = image_path\n",
    "        self.label_path = label_path\n",
    "        self.images, self.labels = self._read_images_and_labels()\n",
    "        self.images = self.images / 126.0\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def _read_images_and_labels(self):\n",
    "        with open(self.image_path,'rb') as f:\n",
    "            magic, size = struct.unpack(\">II\", f.read(8))\n",
    "            nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "            print(\"label size: \", size)\n",
    "\n",
    "            data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "            data = data.reshape((size, nrows*ncols))\n",
    "\n",
    "        with open(self.label_path, 'rb') as f:\n",
    "            magic, size = struct.unpack(\">II\", f.read(8))\n",
    "            print(\"label size: \", size)\n",
    "            labels = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        \n",
    "        return data, labels\n",
    "    \n",
    "    def initilize_epoch(self):\n",
    "        self.cur_idx = 0\n",
    "        pertumation_idxs = np.random.permutation(self.images.shape[0])\n",
    "        self.images = self.images[pertumation_idxs, :]\n",
    "        self.labels = self.labels[pertumation_idxs]\n",
    "        \n",
    "    def get_train_batch(self):\n",
    "        input_feed = {}\n",
    "        \n",
    "        if self.cur_idx + self.batch_size > self.images.shape[0]:\n",
    "            has_next = False\n",
    "            input_feed[self.model.images.name] = self.images[self.cur_idx: self.images.shape[0]]\n",
    "            input_feed[self.model.labels.name] = self.labels[self.cur_idx: self.images.shape[0]]\n",
    "            \n",
    "            if \"random\" in self.model.net_struct:\n",
    "                input_feed[self.model.random_1.name] = np.random.normal(size=(self.model.input_size, self.model.hidden_size))\n",
    "                input_feed[self.model.random_2.name] = np.random.normal(size=(self.model.hidden_size, self.model.hidden_size)) \n",
    "                input_feed[self.model.random_3.name] = np.random.normal(size=(self.model.hidden_size, 10)) \n",
    "    \n",
    "            return input_feed, has_next\n",
    "        else:\n",
    "            has_next = True\n",
    "            input_feed[self.model.images.name] = self.images[self.cur_idx: self.cur_idx+self.batch_size]\n",
    "            input_feed[self.model.labels.name] = self.labels[self.cur_idx: self.cur_idx+self.batch_size]\n",
    "            \n",
    "            if \"random\" in self.model.net_struct:\n",
    "                input_feed[self.model.random_1.name] = np.random.normal(size=(self.model.input_size, self.model.hidden_size))\n",
    "                input_feed[self.model.random_2.name] = np.random.normal(size=(self.model.hidden_size, self.model.hidden_size)) \n",
    "                input_feed[self.model.random_3.name] = np.random.normal(size=(self.model.hidden_size, 10)) \n",
    "                \n",
    "            self.cur_idx += self.batch_size\n",
    "            return input_feed, has_next\n",
    "        \n",
    "    \n",
    "    def get_test_batch(self):\n",
    "        input_feed = {}\n",
    "            \n",
    "        input_feed[self.model.images.name] = self.images[0: self.images.shape[0]]\n",
    "        input_feed[self.model.labels.name] = self.labels[0: self.images.shape[0]]\n",
    "        \n",
    "        if \"random\" in self.model.net_struct:\n",
    "            input_feed[self.model.random_1.name] = np.random.normal(size=(self.model.input_size, self.model.hidden_size))\n",
    "            input_feed[self.model.random_2.name] = np.random.normal(size=(self.model.hidden_size, self.model.hidden_size)) \n",
    "            input_feed[self.model.random_3.name] = np.random.normal(size=(self.model.hidden_size, 10)) \n",
    "            \n",
    "        return input_feed\n",
    "        \n",
    "def train():\n",
    "    # place for all hyperparamters and settings\n",
    "    image_path = \"train-images-idx3-ubyte\"\n",
    "    label_path = \"train-labels-idx1-ubyte\"\n",
    "    ckpt_file = \"\"\n",
    "    epochs = 500\n",
    "    learning_rate = 1e-3\n",
    "    batch_size = 100\n",
    "    input_size = 28*28\n",
    "    hidden_size = 200\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    \n",
    "    with tf.Session(config=config) as sess:\n",
    "        model = MnistClassification(input_size, hidden_size, learning_rate, net_struct=\"random_factor\", forward_only=False)\n",
    "        dataset = Dataset(model, image_path, label_path, batch_size)\n",
    "        init_op = tf.initialize_all_variables()\n",
    "        sess.run(init_op)\n",
    "        for i in range(epochs):\n",
    "            print(\"In epoch: \", i)\n",
    "            has_next = True\n",
    "            idx = 0\n",
    "            \n",
    "            dataset.initilize_epoch()\n",
    "            while has_next:\n",
    "                idx+=1\n",
    "\n",
    "                input_feed, has_next = dataset.get_train_batch()\n",
    "                #print(input_feed.keys())\n",
    "\n",
    "                loss, accu = model.step(sess, input_feed, forward_only=False)\n",
    "                \n",
    "                if idx % 10 == 0:\n",
    "                    print(\"loss: %.3f\\t accuracy: %.3f \"%(loss/batch_size, accu))\n",
    "        \n",
    "        #ckpt_path = \"./\" + \"mnist_det_weight.ckpt\"\n",
    "        #model.saver.save(sess, ckpt_path, global_step=model.global_step)\n",
    "                \n",
    "    \n",
    "        # test file\n",
    "        image_path = \"t10k-images-idx3-ubyte\"\n",
    "        label_path = \"t10k-labels-idx1-ubyte\"\n",
    "        dataset = Dataset(model, image_path, label_path, batch_size)\n",
    "        input_feed = dataset.get_test_batch()\n",
    "        accu = model.step(sess, input_feed, forward_only=True)\n",
    "        print(\"accuracy: \", accu)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label size:  60000\n",
      "label size:  60000\n",
      "In epoch:  0\n",
      "loss: 15.099\t accuracy: 0.060 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.259\t accuracy: 0.110 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 13.701\t accuracy: 0.150 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.021\t accuracy: 0.130 \n",
      "loss: 14.187\t accuracy: 0.120 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.636\t accuracy: 0.090 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.171\t accuracy: 0.120 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.757\t accuracy: 0.200 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.206\t accuracy: 0.110 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.701\t accuracy: 0.150 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.825\t accuracy: 0.080 \n",
      "loss: 13.058\t accuracy: 0.190 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "In epoch:  1\n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 15.796\t accuracy: 0.020 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.309\t accuracy: 0.110 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.584\t accuracy: 0.090 \n",
      "loss: 15.795\t accuracy: 0.020 \n",
      "loss: 14.045\t accuracy: 0.120 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.884\t accuracy: 0.070 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.892\t accuracy: 0.130 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.588\t accuracy: 0.080 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.808\t accuracy: 0.080 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.738\t accuracy: 0.080 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.334\t accuracy: 0.100 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.675\t accuracy: 0.080 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 15.796\t accuracy: 0.020 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "loss: 15.699\t accuracy: 0.020 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 15.463\t accuracy: 0.040 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 15.796\t accuracy: 0.020 \n",
      "In epoch:  2\n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.996\t accuracy: 0.070 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 14.347\t accuracy: 0.110 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.427\t accuracy: 0.100 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 13.006\t accuracy: 0.180 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.938\t accuracy: 0.070 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 15.796\t accuracy: 0.020 \n",
      "loss: 15.133\t accuracy: 0.060 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 15.485\t accuracy: 0.030 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 12.938\t accuracy: 0.190 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.034\t accuracy: 0.120 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.777\t accuracy: 0.080 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.989\t accuracy: 0.070 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.795\t accuracy: 0.080 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "In epoch:  3\n",
      "loss: 14.334\t accuracy: 0.110 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 12.944\t accuracy: 0.190 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.446\t accuracy: 0.100 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 14.858\t accuracy: 0.070 \n",
      "loss: 15.031\t accuracy: 0.060 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.053\t accuracy: 0.120 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.359\t accuracy: 0.100 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.861\t accuracy: 0.140 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.182\t accuracy: 0.120 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.814\t accuracy: 0.080 \n",
      "loss: 13.965\t accuracy: 0.130 \n",
      "loss: 14.183\t accuracy: 0.120 \n",
      "loss: 12.772\t accuracy: 0.200 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.970\t accuracy: 0.070 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 15.474\t accuracy: 0.040 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.428\t accuracy: 0.100 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 15.252\t accuracy: 0.050 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "In epoch:  4\n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.827\t accuracy: 0.080 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 15.209\t accuracy: 0.050 \n",
      "loss: 13.445\t accuracy: 0.160 \n",
      "loss: 15.213\t accuracy: 0.050 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.829\t accuracy: 0.080 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.557\t accuracy: 0.150 \n",
      "loss: 14.143\t accuracy: 0.120 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 15.275\t accuracy: 0.050 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.663\t accuracy: 0.090 \n",
      "loss: 14.296\t accuracy: 0.100 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.697\t accuracy: 0.150 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "In epoch:  5\n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.250\t accuracy: 0.170 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 13.218\t accuracy: 0.180 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.567\t accuracy: 0.150 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "loss: 14.019\t accuracy: 0.130 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.665\t accuracy: 0.090 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.715\t accuracy: 0.140 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.686\t accuracy: 0.150 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 15.134\t accuracy: 0.060 \n",
      "loss: 13.763\t accuracy: 0.140 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "In epoch:  6\n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.989\t accuracy: 0.070 \n",
      "loss: 14.410\t accuracy: 0.100 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.300\t accuracy: 0.110 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.074\t accuracy: 0.120 \n",
      "loss: 15.473\t accuracy: 0.040 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.020\t accuracy: 0.130 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 15.635\t accuracy: 0.030 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 14.517\t accuracy: 0.090 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.297\t accuracy: 0.100 \n",
      "loss: 12.971\t accuracy: 0.190 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.750\t accuracy: 0.140 \n",
      "loss: 13.919\t accuracy: 0.120 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "In epoch:  7\n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.347\t accuracy: 0.110 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.831\t accuracy: 0.080 \n",
      "loss: 14.668\t accuracy: 0.090 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.542\t accuracy: 0.160 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.097\t accuracy: 0.180 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 15.312\t accuracy: 0.050 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.339\t accuracy: 0.230 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.402\t accuracy: 0.230 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 11.767\t accuracy: 0.270 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.958\t accuracy: 0.130 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 13.981\t accuracy: 0.130 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.561\t accuracy: 0.150 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "In epoch:  8\n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.277\t accuracy: 0.170 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.507\t accuracy: 0.100 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 12.407\t accuracy: 0.230 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 14.184\t accuracy: 0.120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.432\t accuracy: 0.220 \n",
      "loss: 14.555\t accuracy: 0.090 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.993\t accuracy: 0.070 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "In epoch:  9\n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 14.181\t accuracy: 0.120 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.421\t accuracy: 0.160 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.537\t accuracy: 0.160 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.167\t accuracy: 0.180 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 14.866\t accuracy: 0.070 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "In epoch:  10\n",
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 14.324\t accuracy: 0.110 \n",
      "loss: 12.095\t accuracy: 0.250 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.696\t accuracy: 0.080 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 13.754\t accuracy: 0.140 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 11.707\t accuracy: 0.270 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.940\t accuracy: 0.130 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.314\t accuracy: 0.110 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 12.576\t accuracy: 0.220 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 13.537\t accuracy: 0.160 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.708\t accuracy: 0.140 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.306\t accuracy: 0.230 \n",
      "loss: 13.305\t accuracy: 0.170 \n",
      "loss: 11.676\t accuracy: 0.270 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.656\t accuracy: 0.150 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 13.836\t accuracy: 0.140 \n",
      "In epoch:  11\n",
      "loss: 14.088\t accuracy: 0.120 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 15.151\t accuracy: 0.060 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.151\t accuracy: 0.180 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.474\t accuracy: 0.160 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.508\t accuracy: 0.160 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.735\t accuracy: 0.210 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 13.611\t accuracy: 0.150 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.229\t accuracy: 0.110 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "In epoch:  12\n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 13.189\t accuracy: 0.180 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.418\t accuracy: 0.220 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 12.313\t accuracy: 0.230 \n",
      "loss: 13.200\t accuracy: 0.180 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 13.381\t accuracy: 0.170 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 12.608\t accuracy: 0.210 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 13.259\t accuracy: 0.170 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.035\t accuracy: 0.120 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 12.588\t accuracy: 0.210 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.986\t accuracy: 0.130 \n",
      "loss: 12.574\t accuracy: 0.220 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.068\t accuracy: 0.120 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "In epoch:  13\n",
      "loss: 13.238\t accuracy: 0.170 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 13.378\t accuracy: 0.170 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 14.990\t accuracy: 0.070 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 12.895\t accuracy: 0.200 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 12.635\t accuracy: 0.210 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.308\t accuracy: 0.170 \n",
      "loss: 14.829\t accuracy: 0.080 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.790\t accuracy: 0.200 \n",
      "loss: 13.701\t accuracy: 0.150 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 14.356\t accuracy: 0.100 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 12.227\t accuracy: 0.240 \n",
      "loss: 12.924\t accuracy: 0.190 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 12.810\t accuracy: 0.200 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.895\t accuracy: 0.200 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.734\t accuracy: 0.210 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.785\t accuracy: 0.200 \n",
      "In epoch:  14\n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.414\t accuracy: 0.230 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.625\t accuracy: 0.270 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 11.410\t accuracy: 0.290 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.890\t accuracy: 0.200 \n",
      "loss: 13.531\t accuracy: 0.160 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 12.545\t accuracy: 0.220 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.417\t accuracy: 0.230 \n",
      "loss: 13.577\t accuracy: 0.150 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "In epoch:  15\n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 11.631\t accuracy: 0.270 \n",
      "loss: 10.780\t accuracy: 0.330 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 12.734\t accuracy: 0.210 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.859\t accuracy: 0.200 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 11.969\t accuracy: 0.250 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.578\t accuracy: 0.220 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 14.667\t accuracy: 0.090 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 12.932\t accuracy: 0.190 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.315\t accuracy: 0.170 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 13.541\t accuracy: 0.160 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 12.864\t accuracy: 0.200 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.704\t accuracy: 0.150 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "In epoch:  16\n",
      "loss: 12.798\t accuracy: 0.200 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 13.422\t accuracy: 0.160 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.433\t accuracy: 0.220 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 12.564\t accuracy: 0.220 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.268\t accuracy: 0.230 \n",
      "loss: 12.100\t accuracy: 0.240 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 13.213\t accuracy: 0.180 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.895\t accuracy: 0.200 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.204\t accuracy: 0.290 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "In epoch:  17\n",
      "loss: 14.506\t accuracy: 0.100 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 12.766\t accuracy: 0.200 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.503\t accuracy: 0.280 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 13.862\t accuracy: 0.140 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.057\t accuracy: 0.250 \n",
      "loss: 12.551\t accuracy: 0.220 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 9.925\t accuracy: 0.380 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.312\t accuracy: 0.230 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.281\t accuracy: 0.300 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 11.767\t accuracy: 0.270 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 12.410\t accuracy: 0.230 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "In epoch:  18\n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 10.515\t accuracy: 0.340 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 10.804\t accuracy: 0.330 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 11.340\t accuracy: 0.290 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 12.285\t accuracy: 0.230 \n",
      "loss: 11.655\t accuracy: 0.270 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 10.635\t accuracy: 0.340 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "In epoch:  19\n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 13.051\t accuracy: 0.190 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 12.415\t accuracy: 0.230 \n",
      "loss: 11.806\t accuracy: 0.260 \n",
      "loss: 14.023\t accuracy: 0.130 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.571\t accuracy: 0.220 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 14.345\t accuracy: 0.110 \n",
      "loss: 13.399\t accuracy: 0.160 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.646\t accuracy: 0.270 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.554\t accuracy: 0.220 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.158\t accuracy: 0.370 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 14.184\t accuracy: 0.120 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 10.026\t accuracy: 0.370 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.387\t accuracy: 0.230 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "In epoch:  20\n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 12.292\t accuracy: 0.230 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.249\t accuracy: 0.240 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 11.424\t accuracy: 0.290 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 10.955\t accuracy: 0.320 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 10.509\t accuracy: 0.340 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 10.421\t accuracy: 0.350 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "In epoch:  21\n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 12.777\t accuracy: 0.200 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.042\t accuracy: 0.310 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.686\t accuracy: 0.270 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 8.381\t accuracy: 0.480 \n",
      "loss: 10.440\t accuracy: 0.350 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.325\t accuracy: 0.350 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 12.572\t accuracy: 0.220 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 13.700\t accuracy: 0.150 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "In epoch:  22\n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 8.059\t accuracy: 0.500 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 10.637\t accuracy: 0.340 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.637\t accuracy: 0.340 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.456\t accuracy: 0.280 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 12.894\t accuracy: 0.200 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "In epoch:  23\n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.089\t accuracy: 0.310 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.817\t accuracy: 0.260 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.832\t accuracy: 0.320 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 12.040\t accuracy: 0.250 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.274\t accuracy: 0.300 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 10.077\t accuracy: 0.370 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.332\t accuracy: 0.290 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 12.252\t accuracy: 0.240 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 13.217\t accuracy: 0.180 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "In epoch:  24\n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.971\t accuracy: 0.250 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.719\t accuracy: 0.330 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.417\t accuracy: 0.290 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.634\t accuracy: 0.340 \n",
      "loss: 8.865\t accuracy: 0.450 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.260\t accuracy: 0.290 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.362\t accuracy: 0.290 \n",
      "loss: 10.643\t accuracy: 0.340 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "In epoch:  25\n",
      "loss: 10.281\t accuracy: 0.360 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.149\t accuracy: 0.370 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 13.378\t accuracy: 0.170 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 12.300\t accuracy: 0.230 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 8.381\t accuracy: 0.480 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.900\t accuracy: 0.260 \n",
      "loss: 11.340\t accuracy: 0.290 \n",
      "loss: 10.908\t accuracy: 0.320 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "In epoch:  26\n",
      "loss: 9.187\t accuracy: 0.430 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 10.964\t accuracy: 0.320 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 12.089\t accuracy: 0.250 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 10.614\t accuracy: 0.340 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.685\t accuracy: 0.270 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.408\t accuracy: 0.340 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 10.893\t accuracy: 0.320 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "In epoch:  27\n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 8.865\t accuracy: 0.450 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 13.539\t accuracy: 0.160 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.832\t accuracy: 0.260 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 9.507\t accuracy: 0.410 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 11.324\t accuracy: 0.290 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.186\t accuracy: 0.360 \n",
      "loss: 11.160\t accuracy: 0.300 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 10.155\t accuracy: 0.370 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 11.515\t accuracy: 0.280 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "In epoch:  28\n",
      "loss: 10.158\t accuracy: 0.370 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 9.917\t accuracy: 0.380 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 10.637\t accuracy: 0.340 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.050\t accuracy: 0.370 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 8.704\t accuracy: 0.460 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.600\t accuracy: 0.340 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.231\t accuracy: 0.290 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 11.116\t accuracy: 0.310 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.026\t accuracy: 0.250 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 9.027\t accuracy: 0.440 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 12.733\t accuracy: 0.210 \n",
      "loss: 9.026\t accuracy: 0.440 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 11.698\t accuracy: 0.270 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 8.704\t accuracy: 0.460 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 9.657\t accuracy: 0.400 \n",
      "In epoch:  29\n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 12.250\t accuracy: 0.240 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 11.184\t accuracy: 0.300 \n",
      "loss: 8.381\t accuracy: 0.480 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 9.026\t accuracy: 0.440 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 9.187\t accuracy: 0.430 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 9.871\t accuracy: 0.380 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 13.181\t accuracy: 0.180 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 8.704\t accuracy: 0.460 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 8.543\t accuracy: 0.470 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 9.187\t accuracy: 0.430 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "In epoch:  30\n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 13.056\t accuracy: 0.190 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 9.039\t accuracy: 0.430 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.695\t accuracy: 0.330 \n",
      "loss: 10.452\t accuracy: 0.350 \n",
      "loss: 11.283\t accuracy: 0.300 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 9.026\t accuracy: 0.440 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 10.900\t accuracy: 0.320 \n",
      "loss: 9.026\t accuracy: 0.440 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 7.092\t accuracy: 0.560 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 8.704\t accuracy: 0.460 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 11.927\t accuracy: 0.260 \n",
      "loss: 11.931\t accuracy: 0.260 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 8.865\t accuracy: 0.450 \n",
      "loss: 11.766\t accuracy: 0.270 \n",
      "loss: 8.865\t accuracy: 0.450 \n",
      "In epoch:  31\n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 8.704\t accuracy: 0.460 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 9.814\t accuracy: 0.390 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 12.411\t accuracy: 0.230 \n",
      "loss: 11.005\t accuracy: 0.310 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.862\t accuracy: 0.320 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 9.801\t accuracy: 0.390 \n",
      "loss: 8.704\t accuracy: 0.460 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.626\t accuracy: 0.340 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 7.737\t accuracy: 0.520 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 10.016\t accuracy: 0.370 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 9.187\t accuracy: 0.430 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 10.483\t accuracy: 0.350 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 9.510\t accuracy: 0.410 \n",
      "loss: 9.547\t accuracy: 0.400 \n",
      "loss: 9.671\t accuracy: 0.400 \n",
      "loss: 8.220\t accuracy: 0.490 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 11.444\t accuracy: 0.290 \n",
      "loss: 10.316\t accuracy: 0.360 \n",
      "loss: 8.865\t accuracy: 0.450 \n",
      "In epoch:  32\n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 7.414\t accuracy: 0.540 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 10.154\t accuracy: 0.370 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 10.960\t accuracy: 0.320 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 9.187\t accuracy: 0.430 \n",
      "loss: 8.224\t accuracy: 0.490 \n",
      "loss: 9.832\t accuracy: 0.390 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 9.187\t accuracy: 0.430 \n",
      "loss: 10.248\t accuracy: 0.360 \n",
      "loss: 9.026\t accuracy: 0.440 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 10.799\t accuracy: 0.330 \n",
      "loss: 10.638\t accuracy: 0.340 \n",
      "loss: 9.993\t accuracy: 0.380 \n",
      "loss: 9.187\t accuracy: 0.430 \n",
      "loss: 9.348\t accuracy: 0.420 \n",
      "loss: 11.588\t accuracy: 0.280 \n",
      "loss: 11.121\t accuracy: 0.310 \n",
      "loss: 11.605\t accuracy: 0.280 \n",
      "loss: 12.089\t accuracy: 0.250 \n",
      "loss: 10.477\t accuracy: 0.350 \n",
      "loss: 12.572\t accuracy: 0.220 \n",
      "loss: 10.154\t accuracy: 0.370 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-105179edd9d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-9f5af853a596>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;31m#print(input_feed.keys())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-9f5af853a596>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, session, input_feed, forward_only)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0moutput_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforward_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/tf2-py2/lib/python2.7/site-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/tf2-py2/lib/python2.7/site-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/tf2-py2/lib/python2.7/site-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/tf2-py2/lib/python2.7/site-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/tf2-py2/lib/python2.7/site-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/tf2-py2/lib/python2.7/site-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()\n",
    "#test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.02610562, -1.01650157,  0.93031428],\n",
       "       [ 0.77697671, -1.34013198, -0.36582006],\n",
       "       [ 0.50928287, -0.67959637,  0.87299247]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(size=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
